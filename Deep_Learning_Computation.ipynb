{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Computation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZ5jlmA9nqi8KMxe26LATO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Deep Learning Computation"
      ],
      "metadata": {
        "id": "Cj6Nogp5wK5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Layers and Blocks"
      ],
      "metadata": {
        "id": "k0JirJE8wPlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this chapter, we will peel back the curtain, digging deeper into the key components of deep learning computation, namely **model construction**, **parameter access and initialization**, **designing custom layers and blocks**, **reading and writing models to disk**, and **leveraging GPUs to achieve dramatic speedups**."
      ],
      "metadata": {
        "id": "C9FYtbO-yMid"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZlJGBcRv5ED"
      },
      "outputs": [],
      "source": [
        "!pip install d2l==0.14.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "ONaZo1RQwVQh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the concept of a neural network *block*.\n",
        "A block could describe a single layer, a component consisting of multiple layers, or the entire model itself!\n",
        "One benefit of working with the block abstraction is that they can be combined into larger artifacts, often recursively."
      ],
      "metadata": {
        "id": "DK9sxRZd510B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code generates a network with one fully-connected hidden layer with 256 units and ReLU activation, followed by a fully-connected output layer with 10 units(no ativation function)."
      ],
      "metadata": {
        "id": "rhWQZ30F4d5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))"
      ],
      "metadata": {
        "id": "Nlu13eGe4Rc9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(2, 20)"
      ],
      "metadata": {
        "id": "35aIpLKP4pxX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIREFJXu4tTy",
        "outputId": "fbde673c-546e-4b65-cc24-d3c37f59cf26"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0105,  0.1099, -0.1435, -0.2687,  0.1066,  0.0962,  0.0775, -0.0327,\n",
              "         -0.0546, -0.1029],\n",
              "        [-0.0261,  0.1240, -0.1577, -0.3801, -0.0700,  0.0934,  0.0618, -0.0407,\n",
              "         -0.1943,  0.0500]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In short, nn.Sequential defines a special kind of Module, the class that presents a block in PyTorch.\n",
        "It maintains an ordered list of constituent Modules.\n",
        "Note that each of the two fully-connected layers is an instance of the Linear class which is itself a subclass of Module."
      ],
      "metadata": {
        "id": "TD3loC0765q_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we implement our own custom block, we briefly summarize the basic functionality that each block must provide:\n",
        "1. Ingest input data as arguments to its forward propagation function.\n",
        "2. Generate an output by having the forward propagation function return a value. Note that the output may have a different shape from the input. For example, the first fully-connected layer in our model above ingests an input of dimension 20 but returns an output of dimension 256.\n",
        "3. Calculate the gradient of its output with respect to its input, which can be accessed via its backpropagation function. Typically this happens automatically.\n",
        "4. Store and provide access to those parameters necessary to execute the forward propagation computation.\n",
        "5. Initialize model parameters as needed.\n"
      ],
      "metadata": {
        "id": "NRrECovu7cLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  # Declare a layer with model parameters. Here, we declare two fully connected layers\n",
        "  def __init__(self):\n",
        "    # Call the constructor of the `MLP` parent class `Module` to perform the necessary initialization.\n",
        "    # In this way, other function arguments can also be specified during class instantiation, such as the model parameters, `params` (to be described later)\n",
        "    super().__init__()\n",
        "    self.hidden = nn.Linear(20, 256) # Hidden layer\n",
        "    self.out = nn.Linear(256, 10) # Output layer\n",
        "\n",
        "  # Define the forward propagation of the model, that is, how to return the required model output based on the input `X`\n",
        "  def forward(self, X):\n",
        "    # Note here we use the functional version ReLU defined in the nn.functional module.\n",
        "    return self.out(F.relu(self.hidden(X)))"
      ],
      "metadata": {
        "id": "p1nhHffv4uLu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that it takes X as the input, calculates the hidden representation with the activation function applied, and outputs its logits.\n",
        "In this MLP implementation, both layers are instance variables.\n",
        "To see why this is reasonable, imagine instantiating two MLPs, net1 and net2, and training them on different data.\n",
        "Naturally, we would expect them to represent two different learned models.\n",
        "\n",
        "Note that unless we implement a new operator, we need not worry about the backpropagation function or parameter initialization. The system will generate these functions automatically."
      ],
      "metadata": {
        "id": "U4tbWfw4ANNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = MLP()\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LcWLi1-_3ip",
        "outputId": "14a7cc36-43e4-4f4b-c939-45bfd9f6d931"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1366, -0.0934,  0.0124, -0.1049, -0.0462, -0.0049, -0.4104, -0.0616,\n",
              "         -0.0580, -0.0597],\n",
              "        [ 0.0501, -0.1042, -0.0759, -0.1686,  0.0723,  0.0270, -0.3685,  0.0066,\n",
              "         -0.0806, -0.1850]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A key virtue of the block abstraction is its versatility. We can subclass a block to create layers (such as the fully-connected layer class), entire models (such as MLP class above), or various components of intermediate complexity."
      ],
      "metadata": {
        "id": "jccbzvVGC6wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can now take a closer look at how the Sequential class works.\n",
        "# two key function : 1. A function to append blocks one by one to a list.\n",
        "# 2. A forward propagation function to pass an input through the chain of blocks, in the same order as they were appended."
      ],
      "metadata": {
        "id": "gVs_dTjsBg1P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MySequential(nn.Module):\n",
        "  def __init__(self, *args):\n",
        "    super().__init__()\n",
        "    for idx, module in enumerate(args):\n",
        "      # Here, `module` is an instance of a `Module` subclass.\n",
        "      # We save it in the member variable `_modules` of the `Module` class, and its type is OrderedDict\n",
        "      self._modules[str(idx)] = module\n",
        "      # you might wonder why every Module possesses a _modules attribute and why we used it rather than just define a Python list ourselves.\n",
        "      # In short the chief advanatge of _modules is that during our module's parameter initialization,\n",
        "      # the system knows to look inside the _modules dictionary to find sub-modules whose parameters also need to be initialized.\n",
        "  def forward(self, X):\n",
        "    # OrderedDict guarantees that memebers will be traversed in the order they were added.\n",
        "    for block in self._modules.values():\n",
        "      X = block(X)\n",
        "    return X"
      ],
      "metadata": {
        "id": "gApXjsQ9Dfnk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n9eMXZtDfGO",
        "outputId": "0daa5ef3-9561-492c-d26b-5504330a435c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0479, -0.2129, -0.0379, -0.0908,  0.1511,  0.2889, -0.2433, -0.1504,\n",
              "          0.3012,  0.0038],\n",
              "        [ 0.0357, -0.1925, -0.1861,  0.0565,  0.1230,  0.2560, -0.2437, -0.2908,\n",
              "          0.1156, -0.0956]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When greater flexibility is required, we will want to define our own blocks.\n",
        "For example, we might want to execute Python's control flow within the forward propagation function.\n",
        "Moreover, we might want to perform arbitrary mathematical operations, not simply relying on predefined neural network layers.\n",
        "Sometimes, however, we might want to incorporate terms that are neither the result of previous layers nor updatable parameters."
      ],
      "metadata": {
        "id": "l6ZBYjNRHQzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedHiddenMLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # Random weight parameters that will not compute gradients and therefore keep constant during training\n",
        "    self.rand_weight = torch.rand((20, 20), requires_grad = False)\n",
        "    self.linear = nn.Linear(20, 20)\n",
        "  \n",
        "  def forward(self, X):\n",
        "    X = self.linear(X)\n",
        "    # Use the created constant parameters, as well as the `relu` and `mm` functions\n",
        "    X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
        "    # Reuse the fully-connected layer. This is equivalent to sharing parameters with two fully-connected layers\n",
        "    X = self.linear(X)\n",
        "    # Control flow\n",
        "    while X.abs().sum() > 1: # testing on the condition its L1 norm is larger than 1\n",
        "      X /= 2 # 왼쪽 변수에 오른쪽 값을 나누고 그 결과를 왼쪾 변수에 할당 ex. a /= b <=> a = a/b\n",
        "    return X.sum()"
      ],
      "metadata": {
        "id": "Gpyq-7VcF2AF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this particular operation may not be useful in any real-world task. Our point is only to show you how to integrate arbitrary code into the flow of your neural network computations."
      ],
      "metadata": {
        "id": "g2GRz1ZlJguS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = FixedHiddenMLP()\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOc4icD1JBhF",
        "outputId": "f1d82123-12ef-480c-bd6a-01c163dc8e94"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.2058, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NestMLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU())\n",
        "    self.linear = nn.Linear(32, 16)\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.linear(self.net(X))\n"
      ],
      "metadata": {
        "id": "c9D8KJ6ZJu-O"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
        "chimera(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVShefYsKIRw",
        "outputId": "e04979cd-329d-4216-910b-3d30d0e4f3fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1079, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "* Layers are blocks\n",
        "* Many layers can comprise a block.\n",
        "* Many blocks can comprise a block.\n",
        "* A block can contain code.\n",
        "* Blocks take care of lots of housekeeping, including parameter initialization and backpropagation.\n",
        "* Sequential concatenations of layers and blocks are handled by the *Sequential* block."
      ],
      "metadata": {
        "id": "LK0BZJS2K4R7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Parameter Management"
      ],
      "metadata": {
        "id": "hwvbYz9ALkqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have chosen an architecture and set our hyperparameters, we proceed to the training loop, where our goal is to find parameter values that minimize our loss function.\n",
        "\n",
        "In this section, we cover the following:\n",
        "* Accessing parameters for debugging, diagnostics, and visualizations.\n",
        "* Parameter initialization.\n",
        "* Sharing parameters across different model components."
      ],
      "metadata": {
        "id": "NpEwxPUIXlj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
        "X = torch.rand(size = (2,4))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHc8okLWKQIH",
        "outputId": "bd5ef360-c4f9-450f-8abd-d45553307f13"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4324],\n",
              "        [0.4051]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# each layer's parameters are conveniently located in its attribute.\n",
        "# We can inspect the parameters of the second fully-connected layers as follows.\n",
        "print(net[2].state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pjZEqKbYQw8",
        "outputId": "7ba94c1e-7055-412c-eba2-35ca867266ae"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('weight', tensor([[-0.3007, -0.1463,  0.1335,  0.2865,  0.3052, -0.1386,  0.3373, -0.1939]])), ('bias', tensor([0.1736]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The following code extracts the bias from the second neural network layer,\n",
        "# which returns a parameter class instance, and further accesses that parameter's value.\n",
        "print(type(net[2].bias))\n",
        "print(net[2].bias)\n",
        "print(net[2].bias.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NVgzsFRYgnA",
        "outputId": "06b37c21-df50-4f30-893b-d0e7dbb36529"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.parameter.Parameter'>\n",
            "Parameter containing:\n",
            "tensor([0.1736], requires_grad=True)\n",
            "tensor([0.1736])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In addition to the value, each parameter also allows us to access the gradient.\n",
        "# Because we have not invoked backpropagation for this network yet, it is in its initial state.\n",
        "net[2].weight.grad == None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiBoGwgRZIzf",
        "outputId": "49a39a05-af53-443f-e90d-2da2d06077f9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Below we demonstrate accessing the parameters of the first fully-connected layer vs. accessing all layers.\n",
        "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
        "print(*[(name, param.shape) for name, param in net.named_parameters()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M6SI1vXZ-i7",
        "outputId": "970b7ce3-7918-4945-ede0-e4735e22e096"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
            "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.state_dict()['2.bias'].data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUqXst1Na4E7",
        "outputId": "7a9c67bf-7af4-4e44-f399-e346eb941e39"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1736])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collecting Parameters from Nested Blocks\n",
        "def block1():\n",
        "  return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
        "                       nn.Linear(8, 4), nn.ReLU())\n",
        "  \n",
        "def block2():\n",
        "  net = nn.Sequential()\n",
        "  for i in range(4):\n",
        "    # Nested here\n",
        "    net.add_module(f'block {i}', block1())\n",
        "  return net"
      ],
      "metadata": {
        "id": "9jzdTQ2Va7NI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgnet = nn.Sequential(block2(), nn.Linear(4,1))\n",
        "rgnet(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GJFm6oKb-4x",
        "outputId": "bb61566d-16fa-43e1-8851-42a2a73f427f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0950],\n",
              "        [0.0954]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rgnet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R8qFZJacDYj",
        "outputId": "576e4e0b-81fa-47a5-a82e-41d83c824358"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (block 0): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 1): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 2): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 3): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the layers are hierarchically nested, we can also access them as though indexing through nested lists. For instance, we can access the first major block, within it the second sub-block, and within that the bias of the first layer, with as follows."
      ],
      "metadata": {
        "id": "5r1NTx-dc8un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rgnet[0][1][0].bias.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wIZ8_cCcGdV",
        "outputId": "b6bf6b48-4bd4-409c-9e00-827a8ef2fb73"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.4028,  0.2159, -0.2295,  0.0572, -0.0388,  0.4746,  0.4848,  0.4638])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, PyTorch initializes weight and bias matrices uniformly by drawing from a range that is computed according to the input and output dimension.\n",
        "PyTorch's nn.init module provides a variety of prest initialization methods.\n",
        "\n",
        "1. Built-in initialization\n",
        "The code below initializes all weight parameters as Gaussian random variables with standard deviation 0.01, while bias parameters cleared to zero."
      ],
      "metadata": {
        "id": "zCdsgRvldRXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_normal(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    nn.init.normal_(m.weight, mean = 0, std = 0.01)\n",
        "    nn.init.zeros_(m.bias)\n",
        "\n",
        "net.apply(init_normal)\n",
        "net[0].weight.data[0], net[0].bias.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVSO2IJFefxh",
        "outputId": "a80acdb3-7fa7-4d16-d05c-f606e69bd6a5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0092, -0.0180, -0.0026,  0.0052]), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can also initialize all the parameters to a given constant value (Say, 1)\n",
        "\n",
        "def init_constant(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    nn.init.constant_(m.weight, 1)\n",
        "    nn.init.zeros_(m.bias)\n",
        "net.apply(init_constant)\n",
        "net[0].weight.data[0], net[0].bias.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH4ujAFXfRdM",
        "outputId": "c6339ccb-a8b3-48ec-b2e2-5b6fcb60293a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1.]), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def xavier(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    nn.init.xavier_uniform_(m.weight)\n",
        "def init_42(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    nn.init.constant_(m.weight, 42)\n",
        "net[0].apply(xavier)\n",
        "net[2].apply(init_42)\n",
        "\n",
        "print(net[0].weight.data[0])\n",
        "print(net[2].weight.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7c1ujH0fp4N",
        "outputId": "83446bf2-5363-42a1-cdcd-07be43cb5554"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.4440, -0.0964,  0.4091, -0.4554])\n",
            "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_init(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    print(\"Init\", *[(name, param.shape) for name, param in m.named_parameters()][0])\n",
        "    nn.init.uniform_(m.weight, -10, 10)\n",
        "    m.weight.data *= m.weight.data.abs() >= 5\n",
        "\n",
        "net.apply(my_init)\n",
        "net[0].weight[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klo38ugggYNb",
        "outputId": "18d4b684-cbe2-43be-d3c3-ce777e1ccbff"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init weight torch.Size([8, 4])\n",
            "Init weight torch.Size([1, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-5.2258, -7.9023,  0.0000, -5.3204],\n",
              "        [ 0.0000, -0.0000,  0.0000, -7.0678]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[0].weight.data[:] += 1\n",
        "net[0].weight.data[0, 0] = 42\n",
        "net[0].weight.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YufUnAThmG6g",
        "outputId": "5292c8e0-e979-4a23-d9b6-b9ba3a5d13b7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([42.0000, -6.9023,  1.0000, -4.3204])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tied Parameters**\n",
        "\n",
        "\n",
        "Often we want to share parameters across multiple layers. Let us see how to do this elegantly. In the following we allocate a dense layer and then use its parameters specifically to set those of another layer."
      ],
      "metadata": {
        "id": "DGmT8AxqmmDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to give the shared layer a name so that we can refer to its parameters\n",
        "shared = nn.Linear(8, 8)\n",
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
        "                    shared, nn.ReLU(),\n",
        "                    shared, nn.ReLU(),\n",
        "                    nn.Linear(8, 1))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR966UH3meYp",
        "outputId": "865eeb54-6799-4df5-8297-dd22567ec342"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4508],\n",
              "        [0.5046]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check whether the parameters are the same\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
        "net[2].weight.data[0, 0] = 100\n",
        "# Make sure that they are actually the same object rather than just having the same value\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzCCIYwpnSWv",
        "outputId": "111e2a07-7671-443d-e855-3d78c232094e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True, True, True, True, True, True])\n",
            "tensor([True, True, True, True, True, True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example shows that the parameters of the second and third layer are tied.\n",
        "\n",
        "They are not just equal, they are represented by the same exact tensor.\n",
        "\n",
        "Thus, if we change one of the parameters, the other one changes, too.\n",
        "\n",
        "You might wonder, when parameters are tied what happens to the grdients?\n",
        "\n",
        "Since the model parameters contain gradients, the gradients of the second hidden layers and the third hidden layer are added together during backpropagation."
      ],
      "metadata": {
        "id": "Nl07BkvuoB3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "* We have several ways to access, initialize, and tie model parameters.\n",
        "* We can use custom initialization."
      ],
      "metadata": {
        "id": "r_1t1rSlrNid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Custom Layers\n",
        "One factor behind deep learning's success is the availability of a wide range of layers that can be composed in creative ways to design architectures suitable for a wide variety of tasks."
      ],
      "metadata": {
        "id": "gFVrBigirwF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# layers without parameters\n",
        "class CenteredLayer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, X):\n",
        "    return X - X.mean()"
      ],
      "metadata": {
        "id": "ESgFv3HXn6G0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = CenteredLayer()\n",
        "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQz8nIRatC3p",
        "outputId": "deaaa9b2-cf68-48de-abea-459f98d08c11"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2., -1.,  0.,  1.,  2.])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
      ],
      "metadata": {
        "id": "UQzwoeNKtOkj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As an extra sanity check, we can send random data through the network and check that the mean is in fact 0.\n",
        "# Because we are dealing with floating point numbers, we may still see a very small nonzero number due to quantization.\n",
        "Y = net(torch.rand(4, 8))\n",
        "Y.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTurRTkKtVmK",
        "outputId": "aed6bfef-fc26-4f96-d020-6490935f17af"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.6566e-09, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinear(nn.Module):\n",
        "  def __init__(self, in_units, units):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.randn(in_units, units))\n",
        "    self.bias = nn.Parameter(torch.randn(units,))\n",
        "  def forward(self, X):\n",
        "    linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
        "    return F.relu(linear)"
      ],
      "metadata": {
        "id": "LsNaX__xtj7M"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear = MyLinear(5, 3)\n",
        "linear.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-pE5PY9um07",
        "outputId": "b61b55fb-d19b-495e-8f81-d9c43f2dff7e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.4056, -0.5313, -0.8475],\n",
              "        [ 0.4193,  0.4344, -0.3667],\n",
              "        [-1.2689, -1.3412,  3.1326],\n",
              "        [-1.6024,  0.1647,  0.4367],\n",
              "        [ 0.5379, -0.2373,  0.3023]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear(torch.rand(2, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u4ZXSgLup2u",
        "outputId": "d98897ee-1b0f-4f9c-83a9-526a40c88c0d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.1714, 0.7388]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
        "net(torch.rand(2, 64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KITepupvuyZz",
        "outputId": "72b7655f-59b8-4d3d-f33d-e2a74492a62d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "* We can design custom layers via the basic layer class. This allows us to define flexible new layers that behave differently from any existing layers in the library.\n",
        "\n",
        "* Once defined, custom layers can be invoked in arbitrary contexts and architectures.\n",
        "\n",
        "* Layers can have local parameters, which can be created through built-in functions."
      ],
      "metadata": {
        "id": "xYC79KI_vadJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 File I/O\n",
        "So far we discussed how to process data and how to **build, train, and test** deep learning models.\n",
        "\n",
        "the learned models that we will want to save the reusults for later use in various contexts(to make predictions in deployment)\n",
        "\n",
        "Additionally, when running a long training process, the best practice is to periodically save intermediate results(checkpointing)\n",
        "\n",
        "**how to load and store both individual weight vectors and entire models.**"
      ],
      "metadata": {
        "id": "iL5NtxS8wbQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(4)\n",
        "torch.save(x, 'x-file')"
      ],
      "metadata": {
        "id": "Ypb7ASc3vXb_"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = torch.load('x-file')\n",
        "x2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEon-w0YyzsZ",
        "outputId": "651257d3-82c4-4204-f564-7eeba9ad0129"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can store a list of tensors and read them back into memory.\n",
        "y = torch.zeros(4)\n",
        "torch.save([x, y], 'x-files')\n",
        "x2, y2 = torch.load('x-files')\n",
        "(x2, y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQXwl8Ngy2cc",
        "outputId": "7e0dc76b-7b7b-40aa-c65f-d836de43c57f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can even write and read a dictionary that maps from strings to tensors.\n",
        "# This is convenient when we want to read or write all the weights in a model.\n",
        "mydict = {'x':x, 'y':y}\n",
        "torch.save(mydict, 'mydict')\n",
        "mydict2 = torch.load('mydict')\n",
        "mydict2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un6UCzIazB7E",
        "outputId": "2c328d83-f558-49df-a8ab-d501258839ca"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The deep learning framework provides built-in functionalities to load and save entire networks. An important detail to note is that this saves model *parameters* and not the entire model."
      ],
      "metadata": {
        "id": "G2KXRz9k09Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden = nn.Linear(20, 256)\n",
        "    self.output = nn.Linear(256, 10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.output(F.relu(self.hidden(x)))"
      ],
      "metadata": {
        "id": "lif6v6bJzPqv"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MLP()\n",
        "X = torch.randn(size = (2, 20))\n",
        "Y = net(X)"
      ],
      "metadata": {
        "id": "yXMvcWit1g7Q"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), 'mlp.params')"
      ],
      "metadata": {
        "id": "LQohGdeB1mFH"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clone = MLP()\n",
        "clone.load_state_dict(torch.load('mlp.params'))\n",
        "clone.eval()\n",
        "# Instead of randomly initializing the model parameters, we read the parameters stored in the file directly."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2EeMnkA1qpB",
        "outputId": "0daaef16-ac1a-4688-daf4-1d147e312421"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_clone = clone(X)\n",
        "Y_clone == Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjNlrJWd1wiJ",
        "outputId": "d232802f-6a32-4a27-bdd9-5d8a5dffcd22"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "* The *save* and *load* functions can be used to perform file I/O for tensor objects.\n",
        "* We can save and load the entire sets of parameters for a network via a parameter dictionary.\n",
        "* Saving the architecture has to be done in code rather than in parameters."
      ],
      "metadata": {
        "id": "8mTy6-ou2Fqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5 GPUs\n",
        "In this section, we begin to discuss how to harness this computational performance for your research.\n",
        "\n",
        "First by using single GPUs and at a later point, how to use multiple GPUs and multiple servers (with multiple GPUs).\n",
        "\n",
        "This is simply to illustrate how data flow between different devices."
      ],
      "metadata": {
        "id": "MbKceGRw429q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "q87XE8Xd9c7I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It should be noted that the cpu device means all physical CPUs and memory.\n",
        "This means that PyTorch's calculations will try to use all CPU cores. However, a gpu device only represents one card and the corresponding memory."
      ],
      "metadata": {
        "id": "yg2K2ew8_-_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.device('cpu'), torch.device('cuda'), torch.device('cuda:1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrwW1JP22EbR",
        "outputId": "1b4bcfac-dcb2-49ed-8961-b5ace2191e62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cpu'), device(type='cuda'), device(type='cuda', index=1))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can query the number of available GPUs.\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BGnlZ9R3KBF",
        "outputId": "505a1112-7fc7-4c10-a92e-1a5a35cffc98"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def try_gpu(i=0):\n",
        "  \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "  if torch.cuda.device_count() >= i+1:\n",
        "    return torch.device(f'cuda:{i}')\n",
        "  return torch.device('cpu')\n",
        "\n",
        "def try_all_gpus():\n",
        "  \"\"\"Return all available GPUs, or [cpu(), ] if no GPU exists.\"\"\"\n",
        "  devices = [torch.device(f'cuda:{i}')\n",
        "          for i in range(torch.cuda.device_count())]\n",
        "  return devices if devices else [torch.device('cpu')]\n",
        "\n",
        "try_gpu(), try_gpu(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3jTmJa0-Wa4",
        "outputId": "f6c0ea42-4fe3-4e96-91de-10ee508307d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0), device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try_all_gpus()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55LJH5OlAtXn",
        "outputId": "f752e4ef-ee80-4bd0-f125-f9fe90c3a791"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[device(type='cuda', index=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# By default, tensors are created on the CPU. We can query the device where the tensor is located.\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhyOGeN7-97C",
        "outputId": "a0084c95-b4ab-47e7-dbb9-3efa2dd039ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to note that whenever we want to operate on multiple terms, they need to be on the same device.\n",
        "\n",
        "For instance, if we sum two tensors, we need to make sure that both arguments live on the same device - otherwise, the framework would not know where to store the result or even how to decide where to perform the computation."
      ],
      "metadata": {
        "id": "-cs0oJuSA-rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones(2, 3, device = try_gpu())\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aerqId7o_MX6",
        "outputId": "b2e81816-98a6-4cc9-91ae-c4bdfaea76e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu 1개만 사용할 수 있는 환경\n",
        "Y = torch.rand(2, 3, device = try_gpu(1))\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ru9oYni_TtW",
        "outputId": "7b0d5108-4d6e-480b-997b-86915fe09537"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7845, 0.4594, 0.4219],\n",
              "        [0.0869, 0.9426, 0.8362]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to compute X + Y, we need to decide where to perform this operation.\n",
        "\n",
        "\n",
        "Since Y lives on the second GPU, we need to move X there before we can add the two.\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "F8DxhbxfCqHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z = X.cuda(1)\n",
        "print(X)\n",
        "print(Z)\n",
        "# cuda:1이 없어서 안되는 걸로 판단됨."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "68acz47lBc6W",
        "outputId": "871fe402-3462-42f0-8bfd-3a50fb20bbea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-045efdabb693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y+Z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "sneEWNBuC1Qs",
        "outputId": "7c4b979e-065c-4dc9-a722-4a7eb186b1a9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d36c33b61743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Z' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z.cuda(1) is Z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "qMTJzDw1C8aI",
        "outputId": "66e44224-eab4-4a37-bd4b-8248ed6704fb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a8fc7bdcccac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Z' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "People use GPUs to do machine learning because they expect them to be fast.\n",
        "\n",
        "But transferring varaibles between device is slow."
      ],
      "metadata": {
        "id": "8hIZHSoHDxrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarly, a neural network model can specify devices\n",
        "net = nn.Sequential(nn.Linear(3, 1))\n",
        "net = net.to(device = try_gpu())"
      ],
      "metadata": {
        "id": "TOicLzJcC-RK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# When the input is a tensor on the GPU, the model will calculate the result on the same GPU.\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KrfE1kpEFEP",
        "outputId": "7bf6e770-2e23-46d0-fa65-b67caaaa3737"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.1002],\n",
              "        [1.1002]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us confirm that the model parameters are stored on the same GPU.\n",
        "net[0].weight.data.device\n",
        "# In short, as long as all data and parameters are on the same device, we can learn models efficiently"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-L29tA1EOe6",
        "outputId": "c77a88a9-053e-446d-9219-fa5aad1c4a93"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "* We can specify devices for storage and calculation, such as the CPU or GPU. By default, data are created in the main memory and then use the CPU for calculations.\n",
        "\n",
        "* The deep learning framework requires all input data for calculation to be on the same device, be it CPU or the same GPU.\n",
        "\n",
        "* You can lose significant performance by moving data without care. A typical mistake is as follows: computing the loss for every minibatch on the GPU and reporting it back to the user on the command line(or logging it in a NumPy ndarray) will trigger a global interpreter lock which stalls all GPUs. It is much better to allocate memory for logging insdie the GPU and only move larger logs."
      ],
      "metadata": {
        "id": "UA81GwJ8Eknk"
      }
    }
  ]
}